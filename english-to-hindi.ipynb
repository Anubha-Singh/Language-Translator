{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T17:20:54.649844Z",
     "iopub.status.busy": "2020-12-06T17:20:54.648978Z",
     "iopub.status.idle": "2020-12-06T17:20:59.833051Z",
     "shell.execute_reply": "2020-12-06T17:20:59.831295Z"
    },
    "id": "f3Melxg5_B2o",
    "papermill": {
     "duration": 5.204898,
     "end_time": "2020-12-06T17:20:59.833187",
     "exception": false,
     "start_time": "2020-12-06T17:20:54.628289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lChLMh2mWfum",
    "papermill": {
     "duration": 0.022399,
     "end_time": "2020-12-06T17:20:59.879203",
     "exception": false,
     "start_time": "2020-12-06T17:20:59.856804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T17:20:59.944426Z",
     "iopub.status.busy": "2020-12-06T17:20:59.933869Z",
     "iopub.status.idle": "2020-12-06T17:20:59.962262Z",
     "shell.execute_reply": "2020-12-06T17:20:59.962886Z"
    },
    "papermill": {
     "duration": 0.060991,
     "end_time": "2020-12-06T17:20:59.963037",
     "exception": false,
     "start_time": "2020-12-06T17:20:59.902046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.LSTM = tf.keras.layers.LSTM(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state_h, state_c = self.LSTM(x, initial_state = hidden)\n",
    "        return output, state_h, state_c\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return (tf.zeros([self.batch_sz, self.enc_units]),\n",
    "                tf.zeros([self.batch_sz, self.enc_units]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LuongAttention(tf.keras.Model):\n",
    "    def __init__(self, rnn_size, attention_func):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        self.attention_func = attention_func\n",
    "\n",
    "        if attention_func not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(\n",
    "                'Unknown attention score function! Must be either dot, general or concat.')\n",
    "\n",
    "        if attention_func == 'general':\n",
    "            # General score function\n",
    "            self.wa = tf.keras.layers.Dense(rnn_size)\n",
    "        elif attention_func == 'concat':\n",
    "            # Concat score function\n",
    "            self.wa = tf.keras.layers.Dense(rnn_size, activation='tanh')\n",
    "            self.va = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, decoder_output, encoder_output):\n",
    "        if self.attention_func == 'dot':\n",
    "            # decoder_output has shape: (batch_size, 1, rnn_size)\n",
    "            # encoder_output has shape: (batch_size, max_len, rnn_size)\n",
    "            # score has shape: (batch_size, 1, max_len)\n",
    "            score = tf.matmul(decoder_output, encoder_output, transpose_b=True)\n",
    "        elif self.attention_func == 'general':\n",
    "\n",
    "            # score has shape: (batch_size, 1, max_len)\n",
    "            score = tf.matmul(decoder_output, self.wa(\n",
    "                encoder_output), transpose_b=True)\n",
    "        elif self.attention_func == 'concat':\n",
    "\n",
    "            decoder_output = tf.tile(\n",
    "                decoder_output, [1, encoder_output.shape[1], 1])\n",
    "\n",
    "            score = self.va(\n",
    "                self.wa(tf.concat((decoder_output, encoder_output), axis=-1)))\n",
    "\n",
    "            # (batch_size, max_len, 1) => (batch_size, 1, max_len)\n",
    "            score = tf.transpose(score, [0, 2, 1])\n",
    "\n",
    "        alignment = tf.nn.softmax(score, axis=2)\n",
    "\n",
    "        # context vector c_t is the weighted average sum of encoder output\n",
    "        context = tf.matmul(alignment, encoder_output)\n",
    "\n",
    "        return context, alignment\n",
    "\n",
    "\n",
    "class LoungDecoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, rnn_size, attention_func):\n",
    "        super(LoungDecoder, self).__init__()\n",
    "        self.attention = LuongAttention(rnn_size, attention_func)\n",
    "        self.rnn_size = rnn_size\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "            rnn_size, return_sequences=True, return_state=True)\n",
    "        self.wc = tf.keras.layers.Dense(rnn_size, activation='tanh')\n",
    "        self.ws = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, sequence, state, encoder_output):\n",
    "        # shape of sequence is (batch_size, 1)\n",
    "        embed = self.embedding(sequence)\n",
    "        # shape of embed becomes (batch_size , 1 , embedding_size)\n",
    "\n",
    "        # the lstm_out has shape (batch_size, 1, rnn_size)\n",
    "        lstm_out, state_h, state_c = self.lstm(embed, initial_state=state)\n",
    "\n",
    "        # Use self.attention to compute the context and alignment vectors\n",
    "        # context vector's shape: (batch_size, 1, rnn_size)\n",
    "        # alignment vector's shape: (batch_size, 1, source_length)\n",
    "        context, alignment = self.attention(lstm_out, encoder_output)\n",
    "\n",
    "        # Combine the context vector and the LSTM output\n",
    "        # Before combined, both have shape of (batch_size, 1, rnn_size),\n",
    "        # so let's squeeze the axis 1 first\n",
    "        # After combined, it will have shape of (batch_size, 2 * rnn_size)\n",
    "        lstm_out = tf.concat(\n",
    "            [tf.squeeze(context, 1), tf.squeeze(lstm_out, 1)], 1)\n",
    "\n",
    "        # lstm_out now has shape (batch_size, rnn_size)\n",
    "        lstm_out = self.wc(lstm_out)\n",
    "\n",
    "        # Finally, it is converted back to vocabulary space: (batch_size, vocab_size)\n",
    "        logits = self.ws(lstm_out)\n",
    "\n",
    "        return logits, state_h, state_c, alignment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "De7lUiCQWzer",
    "papermill": {
     "duration": 0.018827,
     "end_time": "2020-12-06T17:21:00.001904",
     "exception": false,
     "start_time": "2020-12-06T17:20:59.983077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T17:21:00.046479Z",
     "iopub.status.busy": "2020-12-06T17:21:00.045754Z",
     "iopub.status.idle": "2020-12-06T17:21:00.079228Z",
     "shell.execute_reply": "2020-12-06T17:21:00.078448Z"
    },
    "id": "nh_AH5Ul_htn",
    "papermill": {
     "duration": 0.058331,
     "end_time": "2020-12-06T17:21:00.079376",
     "exception": false,
     "start_time": "2020-12-06T17:21:00.021045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lines = io.open('../input/hindienglish/hin.txt', encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "word_pairs = [[a for a in l.split('\\t')]  for l in lines]\n",
    "for i in range(len(word_pairs)):\n",
    "    word_pairs[i] = word_pairs[i][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T17:21:00.118416Z",
     "iopub.status.busy": "2020-12-06T17:21:00.117828Z",
     "iopub.status.idle": "2020-12-06T17:21:00.127592Z",
     "shell.execute_reply": "2020-12-06T17:21:00.128051Z"
    },
    "id": "RATi8m0rDO-J",
    "outputId": "acb6ab29-f495-478f-aed6-8f143fd5424b",
    "papermill": {
     "duration": 0.029049,
     "end_time": "2020-12-06T17:21:00.128182",
     "exception": false,
     "start_time": "2020-12-06T17:21:00.099133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Let me know your address.', 'मुझे अपना पता बतादेना।'],\n",
       " ['My father died of cancer.', 'मेरे पिताजी कैंसर से चल बसे।'],\n",
       " [\"Our team isn't very good.\", 'हमारी टीम बहुत अच्छी नहीं है।'],\n",
       " ['Please wait five minutes.', 'कृपया पाँच मिनट ठहरिए।'],\n",
       " ['She asked us to be quiet.', 'उसने हमें चुप रहने के लिए कहा।'],\n",
       " ['She is an obstinate girl.', 'वह एक ज़िद्दी लड़की है।'],\n",
       " ['She left the baby crying.', 'उसने बच्चे को रोते हुए छोड़ दिया।'],\n",
       " ['She refused to notice me.', 'उसने मुझे ध्यान में लेने से इनकार करदिआ।'],\n",
       " ['Ten years is a long time.', 'दस साल बहुत लम्बा समय होता है।'],\n",
       " ['The doctor felt my pulse.', 'डॉक्टर ने मेरी नब्ज़ ली।']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pairs[1000:1010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-tFq_9kW3pI",
    "papermill": {
     "duration": 0.01572,
     "end_time": "2020-12-06T17:21:00.160341",
     "exception": false,
     "start_time": "2020-12-06T17:21:00.144621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T17:21:00.208272Z",
     "iopub.status.busy": "2020-12-06T17:21:00.205684Z",
     "iopub.status.idle": "2020-12-06T17:21:00.211375Z",
     "shell.execute_reply": "2020-12-06T17:21:00.211877Z"
    },
    "id": "2pEWikt7B7go",
    "papermill": {
     "duration": 0.03556,
     "end_time": "2020-12-06T17:21:00.212003",
     "exception": false,
     "start_time": "2020-12-06T17:21:00.176443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "    if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence_en(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([?.!|,¿])\", r\" \\1 \", s)\n",
    "    s = re.sub(r'[\" \"]+', \" \", s)\n",
    "    s = s.strip()\n",
    "    s = '<start> ' + s + ' <end>'\n",
    "    return s\n",
    "\n",
    "def preprocess_sentence_hn(s):\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([?.!|,¿])\", r\" \\1 \", s)\n",
    "    s = re.sub(r'[\" \"]+', \" \", s)\n",
    "    s = s.strip()\n",
    "    s = '<start> ' + s + ' <end>'\n",
    "    return s  \n",
    "\n",
    "def tokenize(lang):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T17:21:00.253891Z",
     "iopub.status.busy": "2020-12-06T17:21:00.252905Z",
     "iopub.status.idle": "2020-12-06T17:21:00.529007Z",
     "shell.execute_reply": "2020-12-06T17:21:00.529494Z"
    },
    "id": "56Bwd7hjCr1R",
    "papermill": {
     "duration": 0.301009,
     "end_time": "2020-12-06T17:21:00.529657",
     "exception": false,
     "start_time": "2020-12-06T17:21:00.228648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp_lang = [preprocess_sentence_en(p[0]) for p in word_pairs]\n",
    "target_lang = [preprocess_sentence_hn(p[1]) for p in word_pairs]\n",
    "\n",
    "input_tensor, input_lang_tokenizer = tokenize(inp_lang)\n",
    "target_tensor, target_lang_tokenizer = tokenize(target_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T17:21:00.569457Z",
     "iopub.status.busy": "2020-12-06T17:21:00.568640Z",
     "iopub.status.idle": "2020-12-06T17:21:00.571870Z",
     "shell.execute_reply": "2020-12-06T17:21:00.572549Z"
    },
    "id": "GqW3iZn0DC-D",
    "outputId": "7555afc6-7910-4db8-a5e3-d4316e5afa84",
    "papermill": {
     "duration": 0.026347,
     "end_time": "2020-12-06T17:21:00.572717",
     "exception": false,
     "start_time": "2020-12-06T17:21:00.546370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2923, 27)\n",
      "(2923, 29)\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor.shape)\n",
    "print(target_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T17:21:00.628834Z",
     "iopub.status.busy": "2020-12-06T17:21:00.627979Z",
     "iopub.status.idle": "2020-12-06T17:21:00.630820Z",
     "shell.execute_reply": "2020-12-06T17:21:00.632430Z"
    },
    "id": "yFpjp8Q3FxeC",
    "papermill": {
     "duration": 0.034365,
     "end_time": "2020-12-06T17:21:00.632613",
     "exception": false,
     "start_time": "2020-12-06T17:21:00.598248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T17:21:00.692690Z",
     "iopub.status.busy": "2020-12-06T17:21:00.691891Z",
     "iopub.status.idle": "2020-12-06T17:21:00.747757Z",
     "shell.execute_reply": "2020-12-06T17:21:00.748382Z"
    },
    "id": "Ps7qdvGvHs8w",
    "papermill": {
     "duration": 0.091823,
     "end_time": "2020-12-06T17:21:00.748557",
     "exception": false,
     "start_time": "2020-12-06T17:21:00.656734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(input_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(target_lang_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor, target_tensor)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CduBk2LAW-Ud",
    "papermill": {
     "duration": 0.025352,
     "end_time": "2020-12-06T17:21:00.800022",
     "exception": false,
     "start_time": "2020-12-06T17:21:00.774670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Initialize Encoder and Decoder models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T17:21:00.856797Z",
     "iopub.status.busy": "2020-12-06T17:21:00.856132Z",
     "iopub.status.idle": "2020-12-06T17:21:00.900355Z",
     "shell.execute_reply": "2020-12-06T17:21:00.899784Z"
    },
    "id": "i71bbjjJIVmz",
    "papermill": {
     "duration": 0.074892,
     "end_time": "2020-12-06T17:21:00.900466",
     "exception": false,
     "start_time": "2020-12-06T17:21:00.825574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "attention_decoder = LoungDecoder(vocab_tar_size, embedding_dim, units, 'concat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T17:21:00.943790Z",
     "iopub.status.busy": "2020-12-06T17:21:00.943152Z",
     "iopub.status.idle": "2020-12-06T17:21:00.947317Z",
     "shell.execute_reply": "2020-12-06T17:21:00.946578Z"
    },
    "id": "eWHEbVEXI72u",
    "papermill": {
     "duration": 0.028529,
     "end_time": "2020-12-06T17:21:00.947455",
     "exception": false,
     "start_time": "2020-12-06T17:21:00.918926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gFpCIlzXIS0",
    "papermill": {
     "duration": 0.017218,
     "end_time": "2020-12-06T17:21:00.983041",
     "exception": false,
     "start_time": "2020-12-06T17:21:00.965823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training\n",
    "\n",
    "## Define single train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T17:21:01.021901Z",
     "iopub.status.busy": "2020-12-06T17:21:01.021258Z",
     "iopub.status.idle": "2020-12-06T17:21:01.033747Z",
     "shell.execute_reply": "2020-12-06T17:21:01.034226Z"
    },
    "id": "aFbs3y9aKtZn",
    "papermill": {
     "duration": 0.033495,
     "end_time": "2020-12-06T17:21:01.034355",
     "exception": false,
     "start_time": "2020-12-06T17:21:01.000860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden_h, enc_hidden_c = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden_h = enc_hidden_h\n",
    "        dec_hidden_c = enc_hidden_c\n",
    "\n",
    "\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            dec_input = tf.expand_dims(targ[:, t-1], 1)\n",
    "      \n",
    "            predictions, dec_hidden_h, dec_hidden_c, _ = attention_decoder(dec_input, (dec_hidden_h , dec_hidden_c), enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + attention_decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T17:21:01.083859Z",
     "iopub.status.busy": "2020-12-06T17:21:01.078781Z",
     "iopub.status.idle": "2020-12-06T17:21:01.089627Z",
     "shell.execute_reply": "2020-12-06T17:21:01.089035Z"
    },
    "id": "vTIVkDrILfdc",
    "papermill": {
     "duration": 0.037572,
     "end_time": "2020-12-06T17:21:01.089736",
     "exception": false,
     "start_time": "2020-12-06T17:21:01.052164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    sentence = preprocess_sentence_en(sentence)\n",
    "\n",
    "    inputs = [input_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = (tf.zeros([1, units]), tf.zeros([1, units]))\n",
    "\n",
    "    enc_out, dec_hidden_h, dec_hidden_c = encoder(inputs, hidden)\n",
    "\n",
    "    dec_input = tf.expand_dims([target_lang_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden_h, dec_hidden_c, _ = attention_decoder(dec_input, (dec_hidden_h, dec_hidden_c), enc_out)\n",
    "\n",
    "\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    # print(predicted_id)\n",
    "        result += target_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if target_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            break\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwhD9KVAXiT4",
    "papermill": {
     "duration": 0.017243,
     "end_time": "2020-12-06T17:21:01.124851",
     "exception": false,
     "start_time": "2020-12-06T17:21:01.107608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T17:21:01.172587Z",
     "iopub.status.busy": "2020-12-06T17:21:01.171943Z",
     "iopub.status.idle": "2020-12-06T22:16:51.455092Z",
     "shell.execute_reply": "2020-12-06T22:16:51.455698Z"
    },
    "id": "o6n-3BzRMXfK",
    "outputId": "d592a1e7-0afe-4a52-e3d1-b7873fee8a54",
    "papermill": {
     "duration": 17750.312722,
     "end_time": "2020-12-06T22:16:51.455869",
     "exception": false,
     "start_time": "2020-12-06T17:21:01.143147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.2512\n",
      "Epoch 1 Loss 1.8286\n",
      "Time taken for 1 epoch 446.14481830596924 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.5934\n",
      "Epoch 2 Loss 1.5179\n",
      "Time taken for 1 epoch 444.03094816207886 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.3246\n",
      "Epoch 3 Loss 1.3990\n",
      "Time taken for 1 epoch 443.4099473953247 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.3630\n",
      "Epoch 4 Loss 1.3086\n",
      "Time taken for 1 epoch 447.27841424942017 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.2071\n",
      "Epoch 5 Loss 1.2272\n",
      "Time taken for 1 epoch 443.7384581565857 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.1014\n",
      "Epoch 6 Loss 1.1434\n",
      "Time taken for 1 epoch 442.9027154445648 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.0438\n",
      "Epoch 7 Loss 1.0629\n",
      "Time taken for 1 epoch 445.6185941696167 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.0521\n",
      "Epoch 8 Loss 0.9796\n",
      "Time taken for 1 epoch 442.891535282135 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.8965\n",
      "Epoch 9 Loss 0.8935\n",
      "Time taken for 1 epoch 440.72787976264954 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.7244\n",
      "Epoch 10 Loss 0.8068\n",
      "Time taken for 1 epoch 444.0262999534607 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.6670\n",
      "Epoch 11 Loss 0.7256\n",
      "Time taken for 1 epoch 447.5452690124512 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.5962\n",
      "Epoch 12 Loss 0.6334\n",
      "Time taken for 1 epoch 440.8773593902588 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.5545\n",
      "Epoch 13 Loss 0.5444\n",
      "Time taken for 1 epoch 441.1314105987549 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.4454\n",
      "Epoch 14 Loss 0.4640\n",
      "Time taken for 1 epoch 443.8210518360138 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.3482\n",
      "Epoch 15 Loss 0.3914\n",
      "Time taken for 1 epoch 442.2587115764618 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.2656\n",
      "Epoch 16 Loss 0.3216\n",
      "Time taken for 1 epoch 443.26559042930603 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.2401\n",
      "Epoch 17 Loss 0.2619\n",
      "Time taken for 1 epoch 444.2368562221527 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.2039\n",
      "Epoch 18 Loss 0.2100\n",
      "Time taken for 1 epoch 444.0716624259949 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.1764\n",
      "Epoch 19 Loss 0.1682\n",
      "Time taken for 1 epoch 440.2523686885834 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.1177\n",
      "Epoch 20 Loss 0.1291\n",
      "Time taken for 1 epoch 449.49454951286316 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0769\n",
      "Epoch 21 Loss 0.1005\n",
      "Time taken for 1 epoch 444.8701400756836 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0696\n",
      "Epoch 22 Loss 0.0802\n",
      "Time taken for 1 epoch 440.8880546092987 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0581\n",
      "Epoch 23 Loss 0.0635\n",
      "Time taken for 1 epoch 443.61525774002075 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0411\n",
      "Epoch 24 Loss 0.0502\n",
      "Time taken for 1 epoch 442.6589443683624 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0381\n",
      "Epoch 25 Loss 0.0412\n",
      "Time taken for 1 epoch 440.9852316379547 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.0318\n",
      "Epoch 26 Loss 0.0339\n",
      "Time taken for 1 epoch 441.2589099407196 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.0173\n",
      "Epoch 27 Loss 0.0291\n",
      "Time taken for 1 epoch 448.0185625553131 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.0204\n",
      "Epoch 28 Loss 0.0271\n",
      "Time taken for 1 epoch 439.71487069129944 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.0219\n",
      "Epoch 29 Loss 0.0253\n",
      "Time taken for 1 epoch 442.86438941955566 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.0149\n",
      "Epoch 30 Loss 0.0222\n",
      "Time taken for 1 epoch 444.5330469608307 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.0079\n",
      "Epoch 31 Loss 0.0217\n",
      "Time taken for 1 epoch 444.34145855903625 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.0177\n",
      "Epoch 32 Loss 0.0207\n",
      "Time taken for 1 epoch 440.51582884788513 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.0225\n",
      "Epoch 33 Loss 0.0193\n",
      "Time taken for 1 epoch 444.48116397857666 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.0122\n",
      "Epoch 34 Loss 0.0189\n",
      "Time taken for 1 epoch 444.33299565315247 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.0143\n",
      "Epoch 35 Loss 0.0182\n",
      "Time taken for 1 epoch 444.8397026062012 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.0099\n",
      "Epoch 36 Loss 0.0180\n",
      "Time taken for 1 epoch 449.6557993888855 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.0121\n",
      "Epoch 37 Loss 0.0173\n",
      "Time taken for 1 epoch 442.8481192588806 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.0125\n",
      "Epoch 38 Loss 0.0179\n",
      "Time taken for 1 epoch 444.30440068244934 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.0080\n",
      "Epoch 39 Loss 0.0175\n",
      "Time taken for 1 epoch 443.21701216697693 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.0117\n",
      "Epoch 40 Loss 0.0178\n",
      "Time taken for 1 epoch 444.5760419368744 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjR-ojIdXnAj",
    "papermill": {
     "duration": 0.031704,
     "end_time": "2020-12-06T22:16:51.518824",
     "exception": false,
     "start_time": "2020-12-06T22:16:51.487120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T22:16:51.587479Z",
     "iopub.status.busy": "2020-12-06T22:16:51.585697Z",
     "iopub.status.idle": "2020-12-06T22:16:51.688836Z",
     "shell.execute_reply": "2020-12-06T22:16:51.689426Z"
    },
    "id": "vxlgVDItMv-R",
    "outputId": "62f0e9ae-33b6-4a1a-b270-9703aee28c98",
    "papermill": {
     "duration": 0.13984,
     "end_time": "2020-12-06T22:16:51.689587",
     "exception": false,
     "start_time": "2020-12-06T22:16:51.549747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> this is book . <end>\n",
      "Predicted translation: यह किताब है। <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'this is book.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T22:16:51.796405Z",
     "iopub.status.busy": "2020-12-06T22:16:51.795597Z",
     "iopub.status.idle": "2020-12-06T22:16:51.940730Z",
     "shell.execute_reply": "2020-12-06T22:16:51.940029Z"
    },
    "id": "LoeTr8YmO5Sf",
    "outputId": "87124aa3-96e2-4420-d566-ba40e8c6c49b",
    "papermill": {
     "duration": 0.206193,
     "end_time": "2020-12-06T22:16:51.940861",
     "exception": false,
     "start_time": "2020-12-06T22:16:51.734668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> are you at home ? <end>\n",
      "Predicted translation: तुम घर पे हो क्या ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'are you at home ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T22:16:52.100202Z",
     "iopub.status.busy": "2020-12-06T22:16:52.099124Z",
     "iopub.status.idle": "2020-12-06T22:16:52.225415Z",
     "shell.execute_reply": "2020-12-06T22:16:52.225976Z"
    },
    "id": "4K6XDGH8PjQ4",
    "outputId": "bbbb725b-45d2-477d-e434-b93137f40f7f",
    "papermill": {
     "duration": 0.203895,
     "end_time": "2020-12-06T22:16:52.226125",
     "exception": false,
     "start_time": "2020-12-06T22:16:52.022230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> what is this ? <end>\n",
      "Predicted translation: यह क्या है ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'what is this ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EqYeWszNaweO",
    "papermill": {
     "duration": 0.045303,
     "end_time": "2020-12-06T22:16:52.317903",
     "exception": false,
     "start_time": "2020-12-06T22:16:52.272600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 17762.001093,
   "end_time": "2020-12-06T22:16:52.570428",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-06T17:20:50.569335",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
