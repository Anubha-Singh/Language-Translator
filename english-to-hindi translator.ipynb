{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:20:43.019203Z",
     "iopub.status.busy": "2020-12-08T18:20:43.018463Z",
     "iopub.status.idle": "2020-12-08T18:20:48.077073Z",
     "shell.execute_reply": "2020-12-08T18:20:48.075692Z"
    },
    "id": "f3Melxg5_B2o",
    "papermill": {
     "duration": 5.078297,
     "end_time": "2020-12-08T18:20:48.077218",
     "exception": false,
     "start_time": "2020-12-08T18:20:42.998921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:20:48.122606Z",
     "iopub.status.busy": "2020-12-08T18:20:48.121123Z",
     "iopub.status.idle": "2020-12-08T18:20:48.147178Z",
     "shell.execute_reply": "2020-12-08T18:20:48.146700Z"
    },
    "papermill": {
     "duration": 0.056364,
     "end_time": "2020-12-08T18:20:48.147283",
     "exception": false,
     "start_time": "2020-12-08T18:20:48.090919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.LSTM = tf.keras.layers.LSTM(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state_h, state_c = self.LSTM(x, initial_state = hidden)\n",
    "        return output, state_h, state_c\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return (tf.zeros([self.batch_sz, self.enc_units]),\n",
    "                tf.zeros([self.batch_sz, self.enc_units]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LuongAttention(tf.keras.Model):\n",
    "    def __init__(self, rnn_size, attention_func):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        self.attention_func = attention_func\n",
    "\n",
    "        if attention_func not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(\n",
    "                'Unknown attention score function! Must be either dot, general or concat.')\n",
    "\n",
    "        if attention_func == 'general':\n",
    "            # General score function\n",
    "            self.wa = tf.keras.layers.Dense(rnn_size)\n",
    "        elif attention_func == 'concat':\n",
    "            # Concat score function\n",
    "            self.wa = tf.keras.layers.Dense(rnn_size, activation='tanh')\n",
    "            self.va = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, decoder_output, encoder_output):\n",
    "        if self.attention_func == 'dot':\n",
    "            # decoder_output has shape: (batch_size, 1, rnn_size)\n",
    "            # encoder_output has shape: (batch_size, max_len, rnn_size)\n",
    "            # score has shape: (batch_size, 1, max_len)\n",
    "            score = tf.matmul(decoder_output, encoder_output, transpose_b=True)\n",
    "        elif self.attention_func == 'general':\n",
    "\n",
    "            # score has shape: (batch_size, 1, max_len)\n",
    "            score = tf.matmul(decoder_output, self.wa(\n",
    "                encoder_output), transpose_b=True)\n",
    "        elif self.attention_func == 'concat':\n",
    "\n",
    "            decoder_output = tf.tile(\n",
    "                decoder_output, [1, encoder_output.shape[1], 1])\n",
    "\n",
    "            score = self.va(\n",
    "                self.wa(tf.concat((decoder_output, encoder_output), axis=-1)))\n",
    "\n",
    "            # (batch_size, max_len, 1) => (batch_size, 1, max_len)\n",
    "            score = tf.transpose(score, [0, 2, 1])\n",
    "\n",
    "        alignment = tf.nn.softmax(score, axis=2)\n",
    "\n",
    "        # context vector c_t is the weighted average sum of encoder output\n",
    "        context = tf.matmul(alignment, encoder_output)\n",
    "\n",
    "        return context, alignment\n",
    "\n",
    "\n",
    "class LoungDecoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, rnn_size, attention_func):\n",
    "        super(LoungDecoder, self).__init__()\n",
    "        self.attention = LuongAttention(rnn_size, attention_func)\n",
    "        self.rnn_size = rnn_size\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "            rnn_size, return_sequences=True, return_state=True)\n",
    "        self.wc = tf.keras.layers.Dense(rnn_size, activation='tanh')\n",
    "        self.ws = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, sequence, state, encoder_output):\n",
    "        # shape of sequence is (batch_size, 1)\n",
    "        embed = self.embedding(sequence)\n",
    "        # shape of embed becomes (batch_size , 1 , embedding_size)\n",
    "\n",
    "        # the lstm_out has shape (batch_size, 1, rnn_size)\n",
    "        lstm_out, state_h, state_c = self.lstm(embed, initial_state=state)\n",
    "\n",
    "        # Use self.attention to compute the context and alignment vectors\n",
    "        # context vector's shape: (batch_size, 1, rnn_size)\n",
    "        # alignment vector's shape: (batch_size, 1, source_length)\n",
    "        context, alignment = self.attention(lstm_out, encoder_output)\n",
    "\n",
    "        # Combine the context vector and the LSTM output\n",
    "        # Before combined, both have shape of (batch_size, 1, rnn_size),\n",
    "        # so let's squeeze the axis 1 first\n",
    "        # After combined, it will have shape of (batch_size, 2 * rnn_size)\n",
    "        lstm_out = tf.concat(\n",
    "            [tf.squeeze(context, 1), tf.squeeze(lstm_out, 1)], 1)\n",
    "\n",
    "        # lstm_out now has shape (batch_size, rnn_size)\n",
    "        lstm_out = self.wc(lstm_out)\n",
    "\n",
    "        # Finally, it is converted back to vocabulary space: (batch_size, vocab_size)\n",
    "        logits = self.ws(lstm_out)\n",
    "\n",
    "        return logits, state_h, state_c, alignment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:20:48.179048Z",
     "iopub.status.busy": "2020-12-08T18:20:48.178439Z",
     "iopub.status.idle": "2020-12-08T18:20:48.214842Z",
     "shell.execute_reply": "2020-12-08T18:20:48.214278Z"
    },
    "id": "nh_AH5Ul_htn",
    "papermill": {
     "duration": 0.054331,
     "end_time": "2020-12-08T18:20:48.214944",
     "exception": false,
     "start_time": "2020-12-08T18:20:48.160613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lines = io.open('../input/hindienglish/hin.txt', encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "word_pairs = [[a for a in l.split('\\t')]  for l in lines]\n",
    "for i in range(len(word_pairs)):\n",
    "    word_pairs[i] = word_pairs[i][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:20:48.249139Z",
     "iopub.status.busy": "2020-12-08T18:20:48.247984Z",
     "iopub.status.idle": "2020-12-08T18:20:48.252411Z",
     "shell.execute_reply": "2020-12-08T18:20:48.251944Z"
    },
    "id": "RATi8m0rDO-J",
    "outputId": "acb6ab29-f495-478f-aed6-8f143fd5424b",
    "papermill": {
     "duration": 0.024125,
     "end_time": "2020-12-08T18:20:48.252500",
     "exception": false,
     "start_time": "2020-12-08T18:20:48.228375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Let me know your address.', 'मुझे अपना पता बतादेना।'],\n",
       " ['My father died of cancer.', 'मेरे पिताजी कैंसर से चल बसे।'],\n",
       " [\"Our team isn't very good.\", 'हमारी टीम बहुत अच्छी नहीं है।'],\n",
       " ['Please wait five minutes.', 'कृपया पाँच मिनट ठहरिए।'],\n",
       " ['She asked us to be quiet.', 'उसने हमें चुप रहने के लिए कहा।'],\n",
       " ['She is an obstinate girl.', 'वह एक ज़िद्दी लड़की है।'],\n",
       " ['She left the baby crying.', 'उसने बच्चे को रोते हुए छोड़ दिया।'],\n",
       " ['She refused to notice me.', 'उसने मुझे ध्यान में लेने से इनकार करदिआ।'],\n",
       " ['Ten years is a long time.', 'दस साल बहुत लम्बा समय होता है।'],\n",
       " ['The doctor felt my pulse.', 'डॉक्टर ने मेरी नब्ज़ ली।']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pairs[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:20:48.291802Z",
     "iopub.status.busy": "2020-12-08T18:20:48.291156Z",
     "iopub.status.idle": "2020-12-08T18:20:48.294551Z",
     "shell.execute_reply": "2020-12-08T18:20:48.295004Z"
    },
    "id": "2pEWikt7B7go",
    "papermill": {
     "duration": 0.028146,
     "end_time": "2020-12-08T18:20:48.295112",
     "exception": false,
     "start_time": "2020-12-08T18:20:48.266966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "    if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence_en(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([?.!|,¿])\", r\" \\1 \", s)\n",
    "    s = re.sub(r'[\" \"]+', \" \", s)\n",
    "    s = s.strip()\n",
    "    s = '<start> ' + s + ' <end>'\n",
    "    return s\n",
    "\n",
    "def preprocess_sentence_hn(s):\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([?.!|,¿])\", r\" \\1 \", s)\n",
    "    s = re.sub(r'[\" \"]+', \" \", s)\n",
    "    s = s.strip()\n",
    "    s = '<start> ' + s + ' <end>'\n",
    "    return s  \n",
    "\n",
    "def tokenize(lang):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:20:48.345305Z",
     "iopub.status.busy": "2020-12-08T18:20:48.335049Z",
     "iopub.status.idle": "2020-12-08T18:20:48.619981Z",
     "shell.execute_reply": "2020-12-08T18:20:48.619447Z"
    },
    "id": "56Bwd7hjCr1R",
    "papermill": {
     "duration": 0.311141,
     "end_time": "2020-12-08T18:20:48.620092",
     "exception": false,
     "start_time": "2020-12-08T18:20:48.308951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp_lang = [preprocess_sentence_en(p[0]) for p in word_pairs]\n",
    "target_lang = [preprocess_sentence_hn(p[1]) for p in word_pairs]\n",
    "\n",
    "input_tensor, input_lang_tokenizer = tokenize(inp_lang)\n",
    "target_tensor, target_lang_tokenizer = tokenize(target_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:20:48.652928Z",
     "iopub.status.busy": "2020-12-08T18:20:48.652137Z",
     "iopub.status.idle": "2020-12-08T18:20:48.657474Z",
     "shell.execute_reply": "2020-12-08T18:20:48.656986Z"
    },
    "id": "GqW3iZn0DC-D",
    "outputId": "7555afc6-7910-4db8-a5e3-d4316e5afa84",
    "papermill": {
     "duration": 0.023271,
     "end_time": "2020-12-08T18:20:48.657566",
     "exception": false,
     "start_time": "2020-12-08T18:20:48.634295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2923, 27)\n",
      "(2923, 29)\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor.shape)\n",
    "print(target_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:20:48.690609Z",
     "iopub.status.busy": "2020-12-08T18:20:48.689865Z",
     "iopub.status.idle": "2020-12-08T18:20:48.692892Z",
     "shell.execute_reply": "2020-12-08T18:20:48.692397Z"
    },
    "id": "yFpjp8Q3FxeC",
    "papermill": {
     "duration": 0.021031,
     "end_time": "2020-12-08T18:20:48.693028",
     "exception": false,
     "start_time": "2020-12-08T18:20:48.671997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:20:51.076603Z",
     "iopub.status.busy": "2020-12-08T18:20:51.075795Z",
     "iopub.status.idle": "2020-12-08T18:20:51.097687Z",
     "shell.execute_reply": "2020-12-08T18:20:51.098157Z"
    },
    "id": "Ps7qdvGvHs8w",
    "papermill": {
     "duration": 2.390719,
     "end_time": "2020-12-08T18:20:51.098300",
     "exception": false,
     "start_time": "2020-12-08T18:20:48.707581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(input_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(target_lang_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor, target_tensor)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:20:51.133444Z",
     "iopub.status.busy": "2020-12-08T18:20:51.132750Z",
     "iopub.status.idle": "2020-12-08T18:20:51.451470Z",
     "shell.execute_reply": "2020-12-08T18:20:51.450195Z"
    },
    "id": "i71bbjjJIVmz",
    "papermill": {
     "duration": 0.337863,
     "end_time": "2020-12-08T18:20:51.451584",
     "exception": false,
     "start_time": "2020-12-08T18:20:51.113721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "attention_decoder = LoungDecoder(vocab_tar_size, embedding_dim, units, 'concat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:20:51.489133Z",
     "iopub.status.busy": "2020-12-08T18:20:51.488410Z",
     "iopub.status.idle": "2020-12-08T18:20:51.492227Z",
     "shell.execute_reply": "2020-12-08T18:20:51.491735Z"
    },
    "id": "eWHEbVEXI72u",
    "papermill": {
     "duration": 0.025291,
     "end_time": "2020-12-08T18:20:51.492315",
     "exception": false,
     "start_time": "2020-12-08T18:20:51.467024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:20:51.531473Z",
     "iopub.status.busy": "2020-12-08T18:20:51.530845Z",
     "iopub.status.idle": "2020-12-08T18:20:51.534235Z",
     "shell.execute_reply": "2020-12-08T18:20:51.533708Z"
    },
    "id": "aFbs3y9aKtZn",
    "papermill": {
     "duration": 0.027135,
     "end_time": "2020-12-08T18:20:51.534320",
     "exception": false,
     "start_time": "2020-12-08T18:20:51.507185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden_h, enc_hidden_c = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden_h = enc_hidden_h\n",
    "        dec_hidden_c = enc_hidden_c\n",
    "\n",
    "\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            dec_input = tf.expand_dims(targ[:, t-1], 1)\n",
    "      \n",
    "            predictions, dec_hidden_h, dec_hidden_c, _ = attention_decoder(dec_input, (dec_hidden_h , dec_hidden_c), enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + attention_decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:20:51.577441Z",
     "iopub.status.busy": "2020-12-08T18:20:51.575830Z",
     "iopub.status.idle": "2020-12-08T18:20:51.578325Z",
     "shell.execute_reply": "2020-12-08T18:20:51.578818Z"
    },
    "id": "vTIVkDrILfdc",
    "papermill": {
     "duration": 0.029429,
     "end_time": "2020-12-08T18:20:51.578924",
     "exception": false,
     "start_time": "2020-12-08T18:20:51.549495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    sentence = preprocess_sentence_en(sentence)\n",
    "\n",
    "    inputs = [input_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = (tf.zeros([1, units]), tf.zeros([1, units]))\n",
    "\n",
    "    enc_out, dec_hidden_h, dec_hidden_c = encoder(inputs, hidden)\n",
    "\n",
    "    dec_input = tf.expand_dims([target_lang_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden_h, dec_hidden_c, _ = attention_decoder(dec_input, (dec_hidden_h, dec_hidden_c), enc_out)\n",
    "\n",
    "\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    # print(predicted_id)\n",
    "        result += target_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if target_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            break\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwhD9KVAXiT4",
    "papermill": {
     "duration": 0.015996,
     "end_time": "2020-12-08T18:20:51.610314",
     "exception": false,
     "start_time": "2020-12-08T18:20:51.594318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:20:51.648958Z",
     "iopub.status.busy": "2020-12-08T18:20:51.648337Z",
     "iopub.status.idle": "2020-12-08T18:34:26.475296Z",
     "shell.execute_reply": "2020-12-08T18:34:26.475885Z"
    },
    "id": "o6n-3BzRMXfK",
    "outputId": "d592a1e7-0afe-4a52-e3d1-b7873fee8a54",
    "papermill": {
     "duration": 814.850372,
     "end_time": "2020-12-08T18:34:26.476062",
     "exception": false,
     "start_time": "2020-12-08T18:20:51.625690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.2336\n",
      "Epoch 1 Loss 1.8139\n",
      "Time taken for 1 epoch 24.435755968093872 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.5709\n",
      "Epoch 2 Loss 1.5177\n",
      "Time taken for 1 epoch 20.7982439994812 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.3747\n",
      "Epoch 3 Loss 1.4039\n",
      "Time taken for 1 epoch 20.22989010810852 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.4094\n",
      "Epoch 4 Loss 1.3132\n",
      "Time taken for 1 epoch 19.479050159454346 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.2657\n",
      "Epoch 5 Loss 1.2219\n",
      "Time taken for 1 epoch 20.98819065093994 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.0810\n",
      "Epoch 6 Loss 1.1385\n",
      "Time taken for 1 epoch 20.22804093360901 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.0991\n",
      "Epoch 7 Loss 1.0503\n",
      "Time taken for 1 epoch 19.960932731628418 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.9349\n",
      "Epoch 8 Loss 0.9649\n",
      "Time taken for 1 epoch 20.835723876953125 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.8777\n",
      "Epoch 9 Loss 0.8756\n",
      "Time taken for 1 epoch 19.80048942565918 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.7618\n",
      "Epoch 10 Loss 0.7869\n",
      "Time taken for 1 epoch 19.892353534698486 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.6428\n",
      "Epoch 11 Loss 0.6945\n",
      "Time taken for 1 epoch 20.469005584716797 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.5754\n",
      "Epoch 12 Loss 0.6065\n",
      "Time taken for 1 epoch 20.050593852996826 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.4957\n",
      "Epoch 13 Loss 0.5209\n",
      "Time taken for 1 epoch 20.077106952667236 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.4041\n",
      "Epoch 14 Loss 0.4444\n",
      "Time taken for 1 epoch 20.548749446868896 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.3546\n",
      "Epoch 15 Loss 0.3745\n",
      "Time taken for 1 epoch 19.95856499671936 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.2588\n",
      "Epoch 16 Loss 0.3061\n",
      "Time taken for 1 epoch 19.820420265197754 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.2056\n",
      "Epoch 17 Loss 0.2460\n",
      "Time taken for 1 epoch 21.020238876342773 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.1504\n",
      "Epoch 18 Loss 0.1963\n",
      "Time taken for 1 epoch 20.282177448272705 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.1327\n",
      "Epoch 19 Loss 0.1566\n",
      "Time taken for 1 epoch 19.68020224571228 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.1007\n",
      "Epoch 20 Loss 0.1239\n",
      "Time taken for 1 epoch 21.097113132476807 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0819\n",
      "Epoch 21 Loss 0.0985\n",
      "Time taken for 1 epoch 19.76072645187378 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0628\n",
      "Epoch 22 Loss 0.0778\n",
      "Time taken for 1 epoch 20.01388168334961 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0563\n",
      "Epoch 23 Loss 0.0633\n",
      "Time taken for 1 epoch 20.655751943588257 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0488\n",
      "Epoch 24 Loss 0.0500\n",
      "Time taken for 1 epoch 19.77387285232544 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0282\n",
      "Epoch 25 Loss 0.0414\n",
      "Time taken for 1 epoch 20.1149320602417 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.0277\n",
      "Epoch 26 Loss 0.0343\n",
      "Time taken for 1 epoch 20.753135442733765 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.0216\n",
      "Epoch 27 Loss 0.0302\n",
      "Time taken for 1 epoch 19.947998046875 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.0238\n",
      "Epoch 28 Loss 0.0271\n",
      "Time taken for 1 epoch 20.001585483551025 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.0186\n",
      "Epoch 29 Loss 0.0252\n",
      "Time taken for 1 epoch 20.526935577392578 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.0173\n",
      "Epoch 30 Loss 0.0234\n",
      "Time taken for 1 epoch 20.12292718887329 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.0191\n",
      "Epoch 31 Loss 0.0215\n",
      "Time taken for 1 epoch 20.028287172317505 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.0149\n",
      "Epoch 32 Loss 0.0206\n",
      "Time taken for 1 epoch 21.105414628982544 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.0143\n",
      "Epoch 33 Loss 0.0202\n",
      "Time taken for 1 epoch 20.040236949920654 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.0089\n",
      "Epoch 34 Loss 0.0193\n",
      "Time taken for 1 epoch 20.338594436645508 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.0115\n",
      "Epoch 35 Loss 0.0197\n",
      "Time taken for 1 epoch 20.39937114715576 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.0200\n",
      "Epoch 36 Loss 0.0181\n",
      "Time taken for 1 epoch 19.816925525665283 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.0150\n",
      "Epoch 37 Loss 0.0184\n",
      "Time taken for 1 epoch 20.56080985069275 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.0121\n",
      "Epoch 38 Loss 0.0183\n",
      "Time taken for 1 epoch 20.759623050689697 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.0076\n",
      "Epoch 39 Loss 0.0190\n",
      "Time taken for 1 epoch 19.77613615989685 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.0170\n",
      "Epoch 40 Loss 0.0199\n",
      "Time taken for 1 epoch 20.627981424331665 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:34:26.567950Z",
     "iopub.status.busy": "2020-12-08T18:34:26.567007Z",
     "iopub.status.idle": "2020-12-08T18:34:26.605666Z",
     "shell.execute_reply": "2020-12-08T18:34:26.606541Z"
    },
    "id": "vxlgVDItMv-R",
    "outputId": "62f0e9ae-33b6-4a1a-b270-9703aee28c98",
    "papermill": {
     "duration": 0.087552,
     "end_time": "2020-12-08T18:34:26.606689",
     "exception": false,
     "start_time": "2020-12-08T18:34:26.519137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> this is book . <end>\n",
      "Predicted translation: यह किताब है। <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'this is book.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:34:26.695698Z",
     "iopub.status.busy": "2020-12-08T18:34:26.694817Z",
     "iopub.status.idle": "2020-12-08T18:34:26.738533Z",
     "shell.execute_reply": "2020-12-08T18:34:26.739571Z"
    },
    "id": "LoeTr8YmO5Sf",
    "outputId": "87124aa3-96e2-4420-d566-ba40e8c6c49b",
    "papermill": {
     "duration": 0.090724,
     "end_time": "2020-12-08T18:34:26.739754",
     "exception": false,
     "start_time": "2020-12-08T18:34:26.649030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> are you at home ? <end>\n",
      "Predicted translation: तुम घर पे हो क्या ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'are you at home ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-08T18:34:26.830226Z",
     "iopub.status.busy": "2020-12-08T18:34:26.829359Z",
     "iopub.status.idle": "2020-12-08T18:34:26.865774Z",
     "shell.execute_reply": "2020-12-08T18:34:26.866707Z"
    },
    "id": "4K6XDGH8PjQ4",
    "outputId": "bbbb725b-45d2-477d-e434-b93137f40f7f",
    "papermill": {
     "duration": 0.084146,
     "end_time": "2020-12-08T18:34:26.866841",
     "exception": false,
     "start_time": "2020-12-08T18:34:26.782695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> what is this ? <end>\n",
      "Predicted translation: यह क्या है ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'what is this ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EqYeWszNaweO",
    "papermill": {
     "duration": 0.043068,
     "end_time": "2020-12-08T18:34:26.953155",
     "exception": false,
     "start_time": "2020-12-08T18:34:26.910087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 829.946173,
   "end_time": "2020-12-08T18:34:28.953729",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-08T18:20:39.007556",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
